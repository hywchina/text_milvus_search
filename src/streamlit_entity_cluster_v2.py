import streamlit as st
import requests
import os
import numpy as np

# â€”â€” é¡µé¢é…ç½® â€”â€” 
st.set_page_config(page_title="Milvus Text Search & Recommend", layout="wide")
st.title("Milvus Text Search & Recommend")

# â€”â€” åˆå§‹åŒ– Session State â€”â€” 
for key, default in [
    ("liked_docs", set()),
    ("disliked_docs", set()),
    ("query_history", []),
    ("doc_embeddings", {}),
    ("search_results", []),
]:
    if key not in st.session_state:
        st.session_state[key] = default

@st.cache_data(show_spinner=False)
def load_file(path):
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

def highlight_text(query, text):
    idx = text.lower().find(query.lower())
    if idx == -1:
        return text
    before = text[:idx]
    match = text[idx:idx+len(query)]
    after = text[idx+len(query):]
    return f"{before}<span style='color:red'>{match}</span>{after}"

def search_milvus(query, search_type, limit, sparse_weight, dense_weight):
    payload = {
        "query": query,
        "limit": limit,
        "sparse_weight": sparse_weight,
        "dense_weight": dense_weight,
    }
    endpoints = {
        "dense": f"{api_url}/dense_search/",
        "sparse": f"{api_url}/sparse_search/",
        "hybrid": f"{api_url}/hybrid_search/",
    }
    try:
        r = requests.post(endpoints[search_type], json=payload, timeout=10)
        r.raise_for_status()
        return r.json().get("results", [])
    except Exception as e:
        st.error(f"æ£€ç´¢æ¥å£è°ƒç”¨å¤±è´¥ï¼š{e}")
        return []

def aggregate_results(results):
    agg = {}
    for r in results:
        p = r["path"]
        if p not in agg or r["score"] > agg[p]["score"]:
            agg[p] = r
    return list(agg.values())

def fetch_doc_embedding(path):
    """
    è¯»å–æ•´ä¸ªæ–‡ä»¶å†…å®¹ï¼Œè°ƒç”¨ POST /embed_dense è·å– 1024 ç»´ç¨ å¯†å‘é‡å¹¶ç¼“å­˜ã€‚
    """
    if path in st.session_state.doc_embeddings:
        return st.session_state.doc_embeddings[path]

    # 1) å…ˆè¯»æ–‡æœ¬
    try:
        text = load_file(path)
    except Exception as e:
        st.warning(f"è¯»å–æ–‡ä»¶å¤±è´¥ï¼Œæ— æ³•è·å– embedding: {e}")
        return None

    # 2) è°ƒç”¨ embed_dense æ¥å£
    EMBEDDING_API_URL = "http://localhost:8001"
    try:
        resp = requests.post(
            f"{EMBEDDING_API_URL}/embed_dense",
            json={"text": text},
            timeout=30
        )
        resp.raise_for_status()
        data = resp.json()
        dense = data.get("dense")
        if not isinstance(dense, list):
            st.warning(f"æ¥å£å‘å›æ ¼å¼å¼‚å¸¸: {data}")
            return None
        emb = np.array(dense, dtype=float)
        # æ ¡éªŒç»´åº¦
        if emb.shape[0] != 1024:
            st.warning(f"è­¦å‘Š: è¿”å›å‘é‡ç»´åº¦ {emb.shape[0]}ï¼Œé¢„æœŸ 1024")
        st.session_state.doc_embeddings[path] = emb
        return emb

    except Exception as e:
        st.warning(f"è·å– embedding å¤±è´¥: {e}")
        return None

def cosine_similarity(a, b):
    if a is None or b is None:
        return 0.0
    norm = np.linalg.norm(a) * np.linalg.norm(b)
    return float(np.dot(a, b) / norm) if norm > 0 else 0.0

def get_recommendations(top_k: int = 5):
    liked = list(st.session_state.liked_docs)
    if not liked:
        return []
    embs = [fetch_doc_embedding(p) for p in liked]
    embs = [e for e in embs if e is not None]
    if not embs:
        return []
    user_vec = np.mean(embs, axis=0)
    candidates = {
        p: emb for p, emb in st.session_state.doc_embeddings.items()
        if p not in st.session_state.liked_docs and p not in st.session_state.disliked_docs
    }
    scored = [(cosine_similarity(user_vec, emb), p) for p, emb in candidates.items()]
    scored.sort(reverse=True, key=lambda x: x[0])
    return [p for _, p in scored[:top_k]]

# â€”â€” UIï¼šFastAPI åœ°å€ & å‚æ•° â€”â€” 
api_url = st.text_input(
    "FastAPI æœåŠ¡åœ°å€ï¼ˆå«ç«¯å£ï¼‰",
    value="http://localhost:8002",
    help="ç”¨äºæ£€ç´¢çš„æœåŠ¡å’Œ embed_dense æœåŠ¡éƒ½åº”æŒ‚åœ¨æ­¤åœ°å€ä¸‹"
).rstrip("/")

query = st.text_input("æŸ¥è¯¢æ–‡æœ¬", "")
search_type = st.selectbox("æ£€ç´¢ç±»å‹", ("dense", "sparse", "hybrid"))
limit = st.slider("è¿”å›ç»“æœæ•°", 1, 20, 5)
sparse_weight = st.slider("ç¨€ç–æƒé‡ (hybrid æœ‰æ•ˆ)", 0.0, 1.0, 1.0)
dense_weight = st.slider("å¯†é›†æƒé‡ (hybrid æœ‰æ•ˆ)", 0.0, 1.0, 1.0)

# â€”â€” æœç´¢æŒ‰é’® â€”â€” 
if st.button("Search"):
    if not query.strip():
        st.error("è¯·è¾“å…¥æŸ¥è¯¢æ–‡æœ¬åå†æ£€ç´¢ã€‚")
    else:
        raw = search_milvus(query, search_type, limit, sparse_weight, dense_weight)
        docs = aggregate_results(raw)
        st.session_state.search_results = docs
        if query not in st.session_state.query_history:
            st.session_state.query_history.append(query)
        # é¢„å– embedding
        for doc in docs:
            fetch_doc_embedding(doc["path"])

# â€”â€” ä¸»åŒºï¼šå±•ç¤ºæœç´¢ç»“æœ â€”â€” 
if st.session_state.search_results:
    st.success(f"å…±å‘½ä¸­ {len(st.session_state.search_results)} ç¯‡æ–‡æ¡£")
    for doc in st.session_state.search_results:
        title = os.path.basename(doc["path"])
        score = doc.get("score", 0.0)
        with st.expander(f"{title} (score: {score:.4f})"):
            snippet = highlight_text(query, doc.get("text", ""))
            st.markdown(snippet, unsafe_allow_html=True)
            st.write(f"**Path:** {doc['path']}")
            st.write(f"**Date:** {doc.get('date','N/A')}")
            if os.path.isfile(doc["path"]):
                try:
                    content = load_file(doc["path"])
                    st.text_area("åŸæ–‡å†…å®¹", content, height=300)
                except Exception as e:
                    st.error(f"è¯»å–åŸæ–‡å¤±è´¥ï¼š{e}")
            else:
                st.warning("åŸæ–‡æ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„æ— æ•ˆ")
            c1, c2 = st.columns([1,1])
            with c1:
                if st.button("ğŸ‘ å–œæ¬¢", key=f"like_{doc['path']}"):
                    st.session_state.liked_docs.add(doc["path"])
                    st.session_state.disliked_docs.discard(doc["path"])
            with c2:
                if st.button("ğŸ‘ ä¸å–œæ¬¢", key=f"dislike_{doc['path']}"):
                    st.session_state.disliked_docs.add(doc["path"])
                    st.session_state.liked_docs.discard(doc["path"])

# â€”â€” ä¾§è¾¹æ ï¼šçŒœä½ å–œæ¬¢ + å†å²æŸ¥è¯¢ â€”â€” 
with st.sidebar:
    st.subheader("ğŸ§  çŒœä½ å–œæ¬¢")
    recs = get_recommendations()
    if recs:
        for p in recs:
            st.markdown(f"- **{os.path.basename(p)}**  \n`{p}`")
    else:
        st.write("æš‚æ— æ¨èï¼Œå…ˆæ ‡è®°ä¸€äº›â€œå–œæ¬¢â€çš„æ–‡æ¡£å§ï¼")

    st.markdown("---")
    st.subheader("ğŸ” å†å²æŸ¥è¯¢")
    for q in reversed(st.session_state.query_history):
        st.write(f"- {q}")
    if st.button("ğŸ§¹ æ¸…é™¤å†å²è®°å½•"):
        st.session_state.query_history.clear()
